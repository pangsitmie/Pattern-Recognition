# -*- coding: utf-8 -*-
"""Coin Toss Distribution

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EkBpeTZ1DRGg3FoxigUeExvNgBQbkjgh
"""
from matplotlib import lines
from sklearn.cluster import KMeans
from scipy.cluster.vq import kmeans
import random as rand
from turtle import color
import numpy as np
import matplotlib.pyplot as plt
import collections
import scipy.stats as stats
from collections import defaultdict


"""# d = number of flips
# n = number of experiments
# prob = probability bias of the coin
# 1.	d = 100 and n =100 using a simulated coin with  = ¼ and ½.
# 2.	d = 100 and n =1000 using a simulated coin with  = 1/3 and ½.
# 3.	d = 100 and n = 10.000 using a simulated coin with  =2/5 and ½.
# 4.	d = 100 and n = 10.000 using a simulated coin with  =3/5 and ½.
"""

# initialize variables
dict1 = dict()
dict2 = dict()
sum = 0
d = 100
n = 10000

centeroid = []


# ------------------------------FUNCTIONS--------------------------
def generate_flip(prob, d):
    heads = []
    tails = []
    for i in range(d):
        if rand.random() < prob:
            List1 = heads.append(1)
        else:
            List2 = tails.append(1)
    return (len(heads))


def k_means(dataset, k):

    key_list = list(dataset)
    size = len(key_list)

    random_list = []
    # centeroid.append(250)
    # centeroid.append(200)
    for i in range(0, k):
        rand_idx = rand.randint(0, size-1)
        print("RAND IDX: ", rand_idx)
        centeroid.append(key_list[rand_idx])
        print("KEY IDX[", rand_idx, "]: ", centeroid[i])
        random_list.append(rand_idx)

    print("Random list: ", random_list)


def distance(x1, x2):
    return (abs(x1-x2))


def grouping(data, c):
    re = [[], []]
    for i in data:
        diff1 = abs(i - c[0])
        diff2 = abs(i - c[1])
        if diff1 == diff2:
            re[0].append(i)
            re[1].append(i)
        elif diff1 < diff2:
            re[0].append(i)
        else:
            re[1].append(i)

    return re


def meaning(group):
    re = np.array([0.0, 0.0])
    for i in range(len(group)):
        sum = 0
        for j in group[i]:
            sum += j
        re[i] = (sum / len(group[i]))
    return re


# def animate(i):
#     x_cals.append(next(index))
#     y_vals.append(random.randint(0.5))

# ani = FuncAnimation(plt.gcf(), animate, interval = 1000)

def animate(frame):
    ax.set_xlim(left=0, right=frame)


try_list = []
# case1
theta1 = 2/5
print("#(head, tails) for", d, "flips and", n, "tries with theta=", theta1)
for times in range(0, n):
    z = generate_flip(theta1, d)
    try_list.append(z)
    if z not in dict1:
        dict1[z] = 1
    else:
        dict1[z] = dict1[z]+1
print("The probability of (Head, Tail)>>>")
for key in dict1:
    # print(key," Head: ", dict1[key]/(n))
    sum += (dict1[key]/(n))
print("The sum of the probabilities is:", sum, '\n')

# case2
theta2 = 1/2
sum = 0
print("#(head, tails) for", d, "flips and", n, "tries with theta=", theta2)
for times in range(0, n):
    z = generate_flip(theta2, d)
    try_list.append(z)
    if z not in dict2:
        dict2[z] = 1
    else:
        dict2[z] = dict2[z]+1
print("The probability of (Head, Tail)>>>")
for key in dict2:
    # print(key," Head: ", dict2[key]/(n))
    sum += (dict2[key]/(n))
print("The sum of the probabilities is:", sum, '\n')


# ------------------------------------------------------
# CASE1 ORDERED DICT (SORTED BAES ON KEYS)
od1 = collections.OrderedDict(sorted(dict1.items()))
print(od1)

# CASE2 ORDERED DICT (SORTED BAES ON KEYS)
od2 = collections.OrderedDict(sorted(dict2.items()))
print(od2)


lists = sorted(od1.items())  # sorted by key, return a list of tuples
x, y = zip(*lists)  # unpack a list of pairs into two tuples

lists = sorted(od2.items())  # sorted by key, return a list of tuples
v, w = zip(*lists)  # unpack a list of pairs into two tuples


output1 = list(od1.values())
probability1 = [i / n for i in output1]
print("sorted x keys of dict1 are:", list(od1.keys()))
print("sorted x values of dict1 are:", output1)
print("all probability in dict1 are:", probability1)

print('\n')
output2 = list(od2.values())
probability2 = [i / n for i in output2]
print("sorted x keys of dict1 are:", od2.keys())
print("sorted x values of dict1 are:", output2)
print("all probability in dict2 are:", probability2)


d3 = collections.OrderedDict(list(od1.items()) + list(od2.items()))
od3 = collections.OrderedDict(sorted(d3.items()))

print("od1: ", od1)
print("od2: ", od2)
print("od3: ", od3)


print("len od od3 ", len(od3))

# generate first 2 random point
k_means(od3, 2)


# -------------------------------PLOTTING THE GRAPH-------------------------------
fig, ax = plt.subplots()

# plot the 1st theta and gausian
l_list1 = [k for k, v in od1.items() for _ in range(v)]
mu1 = np.mean(l_list1)
sigma1 = np.std(l_list1)
plt.bar(list(od1.keys()), probability1)
u = np.linspace(mu1 - 4 * sigma1, mu1 + 4 * sigma1, 100)
ax = plt.twinx()


# plot the 2st theta and gausian
l_list2 = [k for k, v in od2.items() for _ in range(v)]
mu2 = np.mean(l_list2)
sigma2 = np.std(l_list2)
plt.bar(list(od2.keys()), probability2, color='orange')
u2 = np.linspace(mu2 - 4 * sigma2, mu2 + 4 * sigma2, 100)

ax.plot(u, stats.norm.pdf(u, mu1, sigma1))
ax.plot(u2, stats.norm.pdf(u2, mu2, sigma2), color='orange')


ax.set_title(
    f'Histogram of {d} flips, {n} tries, and Theta = {theta1} & {theta2}')
fig.supxlabel('X Number of heads')
fig.supylabel('Probability')


# for i in range(0, len(centeroid)):
#     print(centeroid[i])
#     plt.axvline(x=centeroid[i], ls='--')


# --------------------------------
all_key_list = []
key_list = list(od1)
for i in range(0, len(od1)):
    all_key_list.append(key_list[i])

key_list2 = list(od2)
for i in range(0, len(od2)):
    all_key_list.append(key_list2[i])
print("All keys: ", all_key_list)


cluster1 = []
cluster2 = []
axlines = []
for i in range(0, 20):
    for point in list(try_list):
        x = []
        for idx in range(0, len(centeroid)):
            x.append(distance(centeroid[idx], point))

        if x[0] == x[1]:
            cluster1.append(point)
            cluster2.append(point)
        elif(x[0] < x[1]):
            cluster1.append(point)
        else:
            cluster2.append(point)

    AVG_cluster1 = np.average(cluster1)
    AVG_cluster2 = np.average(cluster2)
    print("cluster1: ", cluster1, "\nAVG cluster1: ", AVG_cluster1)
    print("cluster2: ", cluster2, "\nAVG cluster2: ", AVG_cluster2)
    print("\n")

    centeroid[0] = AVG_cluster1
    axlines.append(centeroid[0])
    centeroid[1] = AVG_cluster2
    axlines.append(centeroid[1])

    od1 = cluster1
    od2 = cluster2

    cluster1.clear()
    cluster2.clear()

    plt.axvline(axlines[0], ls='--', color='blue')
    plt.axvline(axlines[1], ls='--', color='blue')
    plt.axvline((axlines[0]+axlines[1])/2, ls='--', color='red')

    plt.pause(0.25)
    ax.lines.pop(0)
    axlines.clear()


# USING SKLEARN KMEANS LIBRARY
data = np.array(try_list)

kmeans = KMeans(n_clusters=2).fit(data.reshape(-1, 1))
print(kmeans.predict(data.reshape(-1, 1)))

cluster_centers = kmeans.cluster_centers_
print(cluster_centers)
print(type(cluster_centers))
# for cluster in cluster_centers:
#     plt.axvline(x=cluster, ls='-', color='black')

plt.show()
